# (c) 2015-2016 Acellera Ltd http://www.acellera.com
# All Rights Reserved
# Distributed under HTMD Software License Agreement
# No redistribution in whole or part
#
import numpy as np
from scipy import stats
import random
from copy import deepcopy
from scipy.spatial import distance
import logging
import pickle
logger = logging.getLogger(__name__)


class MetricData:
    """ Class used for storing projected trajectories, their clustering and state assignments. Objects of this class
    are constructed by the `project` methods of the other projection classes. Only construct this class if you want to
    load saved data.

    Attributes
    ----------
    dat : numpy.ndarray
        The projected metrics
    ref : numpy.ndarray
        Reference indices to the simulations and frames that generated the metrics
    simlist : numpy.ndarray of :class:`Sim <htmd.simlist.Sim>` objects
        A simulation list generated by the :func:`simlist <htmd.simlist.simlist>` function
    fstep : float
        Size of simulation step in ns
    map : numpy.ndarray
        Contains the mapping from columns in `dat` to atom indices
    parent : :class:`MetricData` object
        The MetricData object that was used to generate this object
    St : numpy.ndarray
        Assignment of simulation frames to clusters
    K : int
        Number of clusters
    N : numpy.ndarray
        Populations of clusters
    Centers : numpy.ndarray
        Centers of clusters
    """
    
    def __init__(self, dat=None, ref=None, map=None, simlist=None, fstep=0, parent=None, file=None):
        self.dat = dat
        self.ref = ref
        self.simlist = simlist
        self.fstep = fstep
        self.map = map

        self.parent = parent

        self.St = None
        self.K = None
        self.N = None
        self.Centers = None

        if file is not None:
            self.load(file)

        self._dataid = random.random()
        self._clusterid = None
        return

    @property
    def trajLengths(self):
        """ Get the lengths of all trajectories

        Returns
        -------
        lens : list
            The lengths of all trajectories in the object

        Examples
        --------
        >>> data.trajLengths
        """
        return np.array([np.size(x, 0) for x in self.dat])

    @property
    def numFrames(self):
        """ Get the total number of frames in all trajectories

        Returns
        -------
        nframes : int
            Total number of frames in all trajectories

        Examples
        --------
        >>> data.numFrames
        """
        return sum(self.trajLengths)

    def cluster(self, clusterobj, mergesmall=None, batchsize=False):
        """ Cluster the metrics

        Parameters
        ----------
        clusterobj : :class:`ClusterMixin <sklearn.cluster.ClusterMixin>` object
            The object of a clustering class from sklearn or with the same interface
        mergesmall : int
            Clusters containing less than `mergesmall` conformations will be joined into their closest well-populated
            neighbour.
        batchsize : int
            Batch sizes bigger than 0 will enable batching.

        Examples
        --------
        >>> from sklearn.cluster import MiniBatchKMeans
        >>> data = MetricDistance.project(sims, 'protein and name CA', 'resname MOL')
        >>> data.cluster(MiniBatchKMeans(n_clusters=1000), mergesmall=5)
        """
        #cluster_obj = coor.cluster_kmeans(self.dat, k=20, stride=1)
        if batchsize > 0:
            lengths = self.trajLengths
            currsum = 0
            starts = [0]
            for i, l in enumerate(lengths):
                currsum += l
                if currsum > batchsize:
                    starts.append(i+1)
                    currsum = 0
            starts.append(len(self.dat))
            for i in range(len(starts) - 1):
                clusterobj.partial_fit(np.concatenate(self.dat[starts[i]:starts[i+1]]))
            labels = []
            for i in range(len(self.dat)):
                labels.append(clusterobj.predict(self.dat[i].astype(np.float32)))
            # This is retarded
            labels = np.concatenate(labels)
        else:
            datconcat = np.concatenate(self.dat)
            if np.ndim(datconcat) == 1:
                datconcat = np.transpose(np.atleast_2d(datconcat))
            import warnings  # Following 3 lines are BS because sklearn refuse to make releases more often than 1 per year...
            with warnings.catch_warnings():
                warnings.simplefilter("ignore")
                clusterobj.fit(datconcat)
            labels = clusterobj.labels_

        uqclu = np.unique(labels)
        self.Centers = clusterobj.cluster_centers_[uqclu, :]
        self.K = len(uqclu)
        # ---- Fixing missing clusters crap...
        map = np.zeros(np.max(labels)+1, dtype=int) * -1
        map[uqclu] = range(self.K)
        labels = map[labels]
        # ------------------------------------
        self.St = self.deconcatenate(labels)
        self.N = np.bincount(labels)

        if mergesmall is not None:
            oldK = self.K
            self.K, self.St, self.Centers, self.N, xxx = _mergeSmallClusters(mergesmall, datconcat, labels, self.Centers, self.N)
            logger.info('Mergesmall removed {} clusters. Original ncluster {}, new ncluster {}.'.format(oldK-self.K, oldK, self.K))
            self.St = self.deconcatenate(self.St)

        self._dataid = random.random()
        self._clusterid = self._dataid
    
    def combine(self, otherdata):
        """ Combines two different metrics into one by concatenating them.

        Parameters
        ----------
        otherdata : :class:`MetricData` object
            Concatenates the metrics of otherdata to the current objects metrics

        Examples
        --------
        >>> dataRMSD = MetricRmsd.project(sims)
        >>> dataDist = MetricSelfDistance.project(sims, 'protein and name CA')
        >>> dataRMSD.combine(dataDist)
        """
        if not np.array_equal(self.trajLengths, otherdata.trajLengths):
            raise NameError('Trying to combine MetricData objects with different number/lengths of trajectories. Check the trajLengths property.')
        for i in range(self.dat):
            if self.simlist[i].simid != otherdata.simlist[i].simid:
                raise NameError('Simulation ids do not match. Cannot combine. Please generate both data from the same simlist')
        for i in range(self.dat):
            self.dat[i] = np.concatenate((self.dat[i], otherdata.dat[i]), axis=1)
        self.map = np.concatenate((self.map, otherdata.map), axis=0)
        self._dataid = random.random()
    
    def dropTraj(self, limits=None, multiple=None, partial=None, idx=None, keepsims=None):
        """ Drops trajectories based on their lengths

        By default, drops all trajectories which are not of statistical mode (most common) length.

        Parameters
        ----------
        limits : list, optional
            Lower and upper limits of trajectory lengths we want to keep. e.g. [100, 500]
        multiple : list, optional
            Drops trajectories whose length is not a multiple of lengths in the list. e.g. [50, 80]
        partial : bool
            Not implemented yet
        idx : list, optional
            A list of trajectory indexes to drop
        keepsims : list of :class:`Sim <htmd.simlist.Sim>` objects
            A list of sims which we want to keep

        Examples
        --------
        >>> data = MetricSelfDistance.project(sims, 'protein and name CA')
        >>> data.dropTraj()
        >>> data.dropTraj(multiple=[100])
        """
        trajLengths = self.trajLengths
        orgNum = len(self.dat)

        if limits is not None:
            drop = (trajLengths < limits[0]) | (trajLengths > limits[1])
        elif multiple is not None:
            if partial is not None:
                raise NameError('TODO')
                pass
            idx = range(orgNum)
            for i in range(len(multiple)):
                idxNew = np.where(np.mod(trajLengths, multiple[i]) != 0)
                idx = np.intersect1d(idxNew, idx)
            drop = np.zeros(len(self.dat), dtype=bool)
            drop[idx] = True
        elif idx is not None:
            drop = np.zeros(len(self.dat), dtype=bool)
            drop[idx] = True
        elif keepsims is not None:
            drop = np.ones(len(self.dat), dtype=bool)
            for i, s in enumerate(self.simlist):
                for k in keepsims:
                    if s == k:
                        drop[i] = False
        else:
            drop = trajLengths != np.array(stats.mode(trajLengths).mode)

        keep = np.invert(drop)
        dropIdx = np.where(drop)[0]

        self.dat = self.dat[keep]
        self.ref = self.ref[keep]
        self.simlist = self.simlist[keep]
        self._dataid = random.random()
        if self.parent:
            self.parent.dat = self.parent.dat[keep]
            self.parent.ref = self.parent.ref[keep]
            self.parent.simlist = self.parent.simlist[keep]
            self.parent._dataid = random.random()

        logger.info('Dropped ' + str(np.sum(drop)) + ' trajectories from ' + str(orgNum) + ' resulting in ' + str(len(self.dat)))
        return dropIdx

    def bootstrap(self, ratio, replacement=False):
        """ Randomly sample a set of trajectories

        Parameters
        ----------
        ratio : float
            What ratio of trajectories to keep. e.g. 0.8
        replacement : bool
            If we should sample with replacement

        Returns
        -------
        bootdata : :class:`MetricData` object
            A new :class:`MetricData` object containing only the sampled trajectories

        Examples
        --------
        >>> data = MetricSelfDistance.project(sims, 'protein and name CA')
        >>> databoot = data.bootstrap(0.8)
        """
        numtraj = len(self.dat)
        numtokeep = int(np.floor(numtraj * ratio))
        if replacement:
            rndtraj = np.random.randint(numtraj, size=numtokeep)
        else:
            rndtraj = np.random.permutation(numtraj)[0:numtokeep]
        rndtraj = sorted(rndtraj)  # Important to keep the sorting! i.e. for data.dropTraj(keepsims=sims)
        bootdata = self.copy()
        bootdata.dat = self.dat[rndtraj]
        bootdata.ref = self.ref[rndtraj]
        bootdata.simlist = self.simlist[rndtraj]
        bootdata._datait = random.random()
        if self.parent is not None:
            bootdata.parent.dat = self.parent.dat[rndtraj]
            bootdata.parent.ref = self.parent.ref[rndtraj]
            bootdata.parent.simlist = self.parent.simlist[rndtraj]
            bootdata.parent._dataid = random.random()
        return bootdata
    
    def plotTrajSizes(self):
        """ Plot the lengths of all trajectories in a sorted bar plot

        Examples
        --------
        >>> data = MetricSelfDistance.project(sims, 'protein and name CA')
        >>> data.plotTrajSizes()
        """
        trajLengths = self.trajLengths
        import matplotlib.pyplot as plt
        plt.ion()
        plt.bar(range(len(trajLengths)), np.sort(trajLengths), color='b', edgecolor='b')
        plt.ylabel('Length of trajectories (in frames)')
        plt.xlabel('Trajectories')
        plt.show()
        return
    
    def splitCols(self):
        raise NameError('Not implemented yet')

    def deconcatenate(self, array):
        sizes = [np.size(x, 0) for x in self.dat]
        indeces = np.cumsum(sizes)
        if np.ndim(array) == 1:
            return np.array(np.split(array, indeces[:-1]))
        else:
            return np.array(np.vsplit(array, indeces[:-1]))

    def abs2rel(self, absFrames):
        """ Convert absolute frame indexes into trajectory index-frame pairs

        Useful when doing calculations on a concatenated data array of all trajectories. When you find a frame of
        interest you can `deconcatenate` the frame index to the corresponding trajectory index-frame pair.

        Parameters
        ----------
        absFrames : list of int
            A list of absolute index frames

        Returns
        -------
        pairs : np.ndarray
            A array where each row is a trajectory index-frame pair

        Examples
        --------
        >>> relidx = data.abs2rel(536)
        """
        if not hasattr(absFrames, "__len__"):
            absFrames = [absFrames]
        endFrames = np.append(0, np.cumsum(self.trajLengths))

        relframe = np.zeros((len(absFrames), 2), dtype=int)
        for i in range(len(absFrames)):
            trajIdx = np.where(absFrames[i] < endFrames)[0][0] - 1
            trajFr = absFrames[i] - endFrames[trajIdx]
            relframe[i, :] = [trajIdx, trajFr]
        return relframe

    def rel2sim(self, relFrames):
        """ Converts trajectory index-frame pairs into Sim-frame pairs

        Parameters
        ----------
        relFrames : 2D np.ndarray
            An array containing in each row trajectory index and frame pairs

        Returns
        -------
        frames : np.ndarray
            An array of :class:`Frame <htmd.simlist.Frame>` objects containing the simulation object, the trajectory
            piece ID and the frame index.

        Examples
        --------
        >>> simframes = data.rel2sim([100, 56])  # 100th simulation frame 56
        """
        from htmd.simlist import Frame
        relFrames = np.array(relFrames)
        if relFrames.ndim == 1:
            relFrames = relFrames[np.newaxis, :]

        sims = []
        frames = []
        for i in range(np.size(relFrames, 0)):
            trajID = relFrames[i, 0]
            trajFrame = relFrames[i, 1]
            sims.append(self.simlist[trajID])
            frames.append(Frame(self.simlist[trajID], self.ref[trajID][trajFrame, 0], self.ref[trajID][trajFrame, 1]))
        return np.array(frames)

    def abs2sim(self, absFrames):
        """ Converts absolute frame indexes into Sim-frame pairs

        Parameters
        ----------
        absFrames : list of int
            A list of absolute index frames

        Returns
        -------
        frames : np.ndarray
            An array of :class:`Frame <htmd.simlist.Frame>` objects containing the simulation object, the trajectory
            piece ID and the frame index.

        Examples
        --------
        >>> simframes = data.abs2sim(563)  # 563rd frame to simulation/frame pairs
        """
        return self.rel2sim(self.abs2rel(absFrames))

    def copy(self):
        """ Produces a deep copy of the object

        Returns
        -------
        data : :class:`MetricData` object
            A copy of the current object

        Examples
        --------
        >>> data = MetricSelfDistance.project(sims, 'protein and name CA')
        >>> data2 = data.copy()
        """
        return deepcopy(self)

    def save(self, filename):
        """ Save a :class:`MetricData` object to disk

        Parameters
        ----------
        filename : str
            Path of the file in which to save the object

        Examples
        --------
        >>> data = MetricSelfDistance.project(sims, 'protein and name CA')
        >>> data.save('./data.dat')
        """
        #np.save(filename, [self.__dict__[k] for k in self.__dict__])
        parentpointer = self.parent
        if self.parent is not None:
            self.parent = self.parent.__dict__

        f = open(filename, 'wb')
        pickle.dump(self.__dict__, f)
        f.close()

        if self.parent is not None:
            self.parent = parentpointer

    def load(self, filename):
        """ Load a :class:`MetricData` object from disk

        Parameters
        ----------
        filename : str
            Path to the saved MetricData object

        Examples
        --------
        >>> data = MetricData()
        >>> data.load('./data.dat')
        """
        #z = np.load(filename)
        #for i, k in enumerate(self.__dict__):
        #    self.__dict__[k] = z[i]
        f = open(filename, 'rb')
        z = pickle.load(f)
        f.close()
        for k in self.__dict__:
            try:
                self.__dict__[k] = z[k]
            except:
                logger.warning('Could not find class property {} in file {}'.format(k, filename))
        if self.parent is not None:
            parentdict = self.parent
            self.parent = MetricData()
            for k in self.parent.__dict__:
                try:
                    self.parent.__dict__[k] = parentdict[k]
                except:
                    logger.warning('Could not find class property {} in file {}'.format(k, filename))

    def _defaultLags(self):
        modelen = stats.mode(self.trajLengths).mode - 1  # -1 to avoid warnings in timescales calc
        if modelen > 20:
            lags = np.append(1, np.round(np.linspace(10, modelen, 25)))
        else:
            lags = np.append(1, np.round(np.linspace(2, modelen, 25)))
        return lags.astype(int)

    def __str__(self):
        s = ''
        for k in sorted(self.__dict__):
            s += '{} = {}, {}\n'.format(k, np.shape(self.__dict__[k]), type(self.__dict__[k]))
        return s


def _mergeSmallClusters(mergesmall, data, stconcat, centers, N, metric=None):
    if data.dtype == 'bool':
        metric = 'hamming'
    else:
        metric = 'euclidean'
    badclusters = N < mergesmall
    goodclusters = np.invert(badclusters)
    N[badclusters] = 0
    badcluidx = np.where(badclusters)[0]
    goodcluidx = np.where(goodclusters)[0]

    if len(badcluidx) == 0:
        return len(N), stconcat, centers, N, badclusters

    # Keep only good centers
    centers = centers[goodclusters, :]

    # Creating a mapping for new cluster numbers as we will have to remove some
    newidx = np.zeros(len(N), dtype=int)
    newidx[goodcluidx] = range(len(goodcluidx))

    # Find all frames which belong to bad clusters
    frames = _ismember(stconcat, badcluidx)
    badframeidx = np.where(frames >= 0)[0]

    # Calculate distance of all frames belonging to bad clusters to the good cluster centers
    dists = distance.cdist(np.atleast_2d(data[badframeidx, :]), np.atleast_2d(centers), metric)
    minidx = np.argmin(dists, axis=1)  # Find closest center. Indexes are relative to goodidx
    newclu = goodcluidx[minidx]  # Back to absolute cluster indexes

    # Reassign bad frames to good clusters
    stconcat[badframeidx] = newclu    # Assign them to new clusters
    stconcat = newidx[stconcat]  # Convert all cluster indexes to the new indexes

    N = np.bincount(stconcat)
    K = len(N)
    return K, stconcat, centers, N, badclusters


def _ismember(a, b):
    bind = {}
    for i, elt in enumerate(list(set(b))):
        bind[elt] = i
    return np.array([bind.get(itm, -1) for itm in a])  # None can be replaced by any other "not in b" value



